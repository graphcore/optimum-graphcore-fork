{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis (using IPUs)\n",
    "\n",
    "https://huggingface.co/blog/sentiment-analysis-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+-----------------------+\n",
      "|          IPUs in p64 attached from other namespaces          |         Board         |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| ID |       Application host       |    Clock     |   Temp    |   Temp    |   Power   |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| 4  |        gbnwp-pod012-3        |   1330MHz    |  32.0 C   |  25.2 C   |  158.3 W  |\n",
      "| 5  |        gbnwp-pod012-3        |   1330MHz    |  29.3 C   |           |           |\n",
      "| 6  |        gbnwp-pod012-3        |   1330MHz    |  31.5 C   |           |           |\n",
      "| 7  |        gbnwp-pod012-3        |   1330MHz    |  30.4 C   |           |           |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| 8  |        gbnwp-pod012-3        |   1330MHz    |  39.9 C   |  30.5 C   |  171.1 W  |\n",
      "| 9  |        gbnwp-pod012-3        |   1330MHz    |  37.6 C   |           |           |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| 20 |        gbnwp-pod012-2        |   1330MHz    |  47.1 C   |  33.0 C   |  278.5 W  |\n",
      "| 21 |        gbnwp-pod012-2        |   1330MHz    |  48.2 C   |           |           |\n",
      "| 22 |        gbnwp-pod012-2        |   1330MHz    |  48.8 C   |           |           |\n",
      "| 23 |        gbnwp-pod012-2        |   1330MHz    |  48.4 C   |           |           |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install -e ../\n",
    "# %pip install emoji==0.6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"POPTORCH_LOG_LEVEL\"] = \"ERR\"\n",
    "import transformers\n",
    "from optimum.graphcore import pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_config = dict(layers_per_ipu=[20], ipus_per_replica=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n",
      "/localdata/alexandrep/paperspace-forks/optimum-graphcore-fork/optimum/graphcore/ipu_configuration.py:148: UserWarning: The \"enable_half_first_order_momentum\" parameter is deprecated\n",
      "  warnings.warn('The \"enable_half_first_order_momentum\" parameter is deprecated')\n",
      "/localdata/alexandrep/paperspace-forks/optimum-graphcore-fork/optimum/graphcore/ipu_configuration.py:140: UserWarning: The \"sharded_execution_for_inference\" parameter is deprecated, sharded execution is always used during inference\n",
      "  warnings.warn(\n",
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated.\n",
      "Graph compilation: 100%|██████████| 100/100 [00:22<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9998660087585449},\n",
       " {'label': 'NEGATIVE', 'score': 0.9990818500518799}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline = pipelines.pipeline(\"sentiment-analysis\", ipu_config_kwargs=inference_config)\n",
    "data = [\"I love you\", \"I hate you\"]\n",
    "sentiment_pipeline(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9356999397277832},\n",
       " {'label': 'POSITIVE', 'score': 0.9859092831611633}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline([\"How are you today?\", \"I'm a little tired, I didn't sleep well, but I hope it gets better\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79deb135b0084de792e42342361fe7aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated.\n",
      "Graph compilation: 100%|██████████| 100/100 [00:38<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'POS', 'score': 0.9902849793434143},\n",
       " {'label': 'NEG', 'score': 0.979720413684845}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model = pipelines.pipeline(\n",
    "    model=\"finiteautomata/bertweet-base-sentiment-analysis\", ipu_config_kwargs=inference_config,\n",
    ")\n",
    "specific_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'NEU', 'score': 0.7505843043327332},\n",
       " {'label': 'NEG', 'score': 0.8974782228469849}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model([\"How are you today?\", \"I'm a little tired, I didn't sleep well, but I hope it gets better\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f136d74022a45b88d0219f481e4b67d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.41k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated.\n",
      "Graph compilation: 100%|██████████| 100/100 [00:37<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_2', 'score': 0.9551451206207275},\n",
       " {'label': 'LABEL_0', 'score': 0.96500563621521}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model = pipelines.pipeline(\n",
    "    model=\"cardiffnlp/twitter-roberta-base-sentiment\",ipu_config_kwargs=inference_config\n",
    ")\n",
    "specific_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'LABEL_1', 'score': 0.8688815236091614},\n",
       " {'label': 'LABEL_1', 'score': 0.47830677032470703}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "specific_model([\"How are you today?\", \"I'm a little tired, I didn't sleep well, but I hope it gets better\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb2c8dd759c94b72873b58c4501b6364",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.55k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated. To change this behaviour, pass the `padding='max_length'` and`max_length=<your desired input length>` arguments to the pipeline function\n",
      "Graph compilation: 100%|██████████| 100/100 [00:36<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.853151261806488},\n",
       " {'label': '1 star', 'score': 0.6354780197143555}]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"nlptown/bert-base-multilingual-uncased-sentiment\"\n",
    "multilingual_model = pipelines.pipeline(\n",
    "    model=model_name, ipu_config_kwargs=inference_config\n",
    ")\n",
    "multilingual_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.5348031520843506},\n",
       " {'label': '3 stars', 'score': 0.7582475543022156}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilingual_model([\"How are you today?\", \"I'm a little tired, I didn't sleep well, but I hope it gets better\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': '5 stars', 'score': 0.5348031520843506},\n",
       " {'label': '3 stars', 'score': 0.7263907790184021}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilingual_model([\"How are you today?\", \"Je suis un peu fatigue, je n'ai pas bien dormi mais j'espere que la journee s'ameliore\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'POSITIVE', 'score': 0.9356999397277832},\n",
       " {'label': 'NEGATIVE', 'score': 0.9287972450256348}]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline([\"How are you today?\", \"Je suis un peu fatigue, je n'ai pas bien dormi mais j'espere que la journee s'ameliore\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26bd0e5b5fab492d833e5022d1ea0692",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/4.07k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No padding arguments specified, so pad to 128 by default. Inputs longer than 128 will be truncated. To change this behaviour, pass the `padding='max_length'` and`max_length=<your desired input length>` arguments to the pipeline function\n",
      "Graph compilation: 100%|██████████| 100/100 [00:20<00:00]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'label': 'love', 'score': 0.9584758281707764},\n",
       " {'label': 'anger', 'score': 0.8243763446807861}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = \"bhadresh-savani/distilbert-base-uncased-emotion\"\n",
    "emotion_model = pipelines.pipeline(model=model_name, ipu_config_kwargs=inference_config)\n",
    "emotion_model(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'label': 'joy', 'score': 0.7177484035491943},\n",
       " {'label': 'joy', 'score': 0.9376221299171448}]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_model([\"How are you today?\", \"I'm a little tired, I didn't sleep well, but I hope it gets better\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationPipeline(\n",
       "    task=text-classification,\n",
       "    modelcard=None,\n",
       "    feature_extractor=None,\n",
       "    framework=pt,\n",
       "    device=cpu,\n",
       "    call_count=3,\n",
       "    tokenizer=PreTrainedTokenizerFast(name_or_path='distilbert-base-uncased-finetuned-sst-2-english', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       "    model.config=DistilBertConfig {\n",
       "  \"_name_or_path\": \"distilbert-base-uncased-finetuned-sst-2-english\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"finetuning_task\": \"sst-2\",\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"NEGATIVE\",\n",
       "    \"1\": \"POSITIVE\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"NEGATIVE\": 0,\n",
       "    \"POSITIVE\": 1\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"vocab_size\": 30522\n",
       "}\n",
       ",\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiment_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationPipeline(\n",
       "    task=text-classification,\n",
       "    modelcard=None,\n",
       "    feature_extractor=None,\n",
       "    framework=pt,\n",
       "    device=cpu,\n",
       "    call_count=2,\n",
       "    tokenizer=PreTrainedTokenizerFast(name_or_path='bhadresh-savani/distilbert-base-uncased-emotion', vocab_size=30522, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       "    model.config=DistilBertConfig {\n",
       "  \"_name_or_path\": \"bhadresh-savani/distilbert-base-uncased-emotion\",\n",
       "  \"activation\": \"gelu\",\n",
       "  \"architectures\": [\n",
       "    \"DistilBertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_dropout\": 0.1,\n",
       "  \"dim\": 768,\n",
       "  \"dropout\": 0.1,\n",
       "  \"hidden_dim\": 3072,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"sadness\",\n",
       "    \"1\": \"joy\",\n",
       "    \"2\": \"love\",\n",
       "    \"3\": \"anger\",\n",
       "    \"4\": \"fear\",\n",
       "    \"5\": \"surprise\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"label2id\": {\n",
       "    \"anger\": 3,\n",
       "    \"fear\": 4,\n",
       "    \"joy\": 1,\n",
       "    \"love\": 2,\n",
       "    \"sadness\": 0,\n",
       "    \"surprise\": 5\n",
       "  },\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"distilbert\",\n",
       "  \"n_heads\": 12,\n",
       "  \"n_layers\": 6,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"qa_dropout\": 0.1,\n",
       "  \"seq_classif_dropout\": 0.2,\n",
       "  \"sinusoidal_pos_embds\": false,\n",
       "  \"tie_weights_\": true,\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"vocab_size\": 30522\n",
       "}\n",
       ",\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emotion_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextClassificationPipeline(\n",
       "    task=text-classification,\n",
       "    modelcard=None,\n",
       "    feature_extractor=None,\n",
       "    framework=pt,\n",
       "    device=cpu,\n",
       "    call_count=3,\n",
       "    tokenizer=PreTrainedTokenizerFast(name_or_path='nlptown/bert-base-multilingual-uncased-sentiment', vocab_size=105879, model_max_len=512, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'}),\n",
       "    model.config=BertConfig {\n",
       "  \"_name_or_path\": \"nlptown/bert-base-multilingual-uncased-sentiment\",\n",
       "  \"_num_labels\": 5,\n",
       "  \"architectures\": [\n",
       "    \"BertForSequenceClassification\"\n",
       "  ],\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"classifier_dropout\": null,\n",
       "  \"directionality\": \"bidi\",\n",
       "  \"finetuning_task\": \"sentiment-analysis\",\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"1 star\",\n",
       "    \"1\": \"2 stars\",\n",
       "    \"2\": \"3 stars\",\n",
       "    \"3\": \"4 stars\",\n",
       "    \"4\": \"5 stars\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"1 star\": 0,\n",
       "    \"2 stars\": 1,\n",
       "    \"3 stars\": 2,\n",
       "    \"4 stars\": 3,\n",
       "    \"5 stars\": 4\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-12,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"model_type\": \"bert\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_fc_size\": 768,\n",
       "  \"pooler_num_attention_heads\": 12,\n",
       "  \"pooler_num_fc_layers\": 3,\n",
       "  \"pooler_size_per_head\": 128,\n",
       "  \"pooler_type\": \"first_token_transform\",\n",
       "  \"position_embedding_type\": \"absolute\",\n",
       "  \"transformers_version\": \"4.20.1\",\n",
       "  \"type_vocab_size\": 2,\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 105879\n",
       "}\n",
       ",\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multilingual_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------------------+------------------------+-----------------+\n",
      "|Attached processes in partition p64|          IPU           |      Board      |\n",
      "+--------+----+--------+------------+----+----------+--------+--------+--------+\n",
      "|  PID   |...d|  Time  |    User    | ID |  Clock   |  Temp  |  Temp  | Power  |\n",
      "+--------+----+--------+------------+----+----------+--------+--------+--------+\n",
      "|3462939 |...t| 4m20s  | alexandrep | 0  | 1330MHz  | 43.3 C | 33.8 C |161.2 W |\n",
      "|3462939 |...t| 4m20s  | alexandrep | 1  | 1330MHz  | 39.6 C |        |        |\n",
      "|3462939 |...t| 4m20s  | alexandrep | 2  | 1330MHz  | 44.7 C |        |        |\n",
      "|3462939 |...t| 4m20s  | alexandrep | 3  | 1330MHz  | 41.3 C |        |        |\n",
      "+--------+----+--------+------------+----+----------+--------+--------+--------+\n",
      "+--------------------------------------------------------------+-----------------------+\n",
      "|          IPUs in p64 attached from other namespaces          |         Board         |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| ID |       Application host       |    Clock     |   Temp    |   Temp    |   Power   |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| 4  |        gbnwp-pod012-3        |   1330MHz    |  32.2 C   |  25.4 C   |  159.1 W  |\n",
      "| 5  |        gbnwp-pod012-3        |   1330MHz    |  29.7 C   |           |           |\n",
      "| 6  |        gbnwp-pod012-3        |   1330MHz    |  31.6 C   |           |           |\n",
      "| 7  |        gbnwp-pod012-3        |   1330MHz    |  30.8 C   |           |           |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n",
      "| 8  |        gbnwp-pod012-3        |   1330MHz    |  40.2 C   |  30.5 C   |  171.9 W  |\n",
      "| 9  |        gbnwp-pod012-3        |   1330MHz    |  37.7 C   |           |           |\n",
      "+----+------------------------------+--------------+-----------+-----------+-----------+\n"
     ]
    }
   ],
   "source": [
    "!gc-monitor --no-card-info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('3.0.0+1145_poptorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "46bde714a99d715eba7e507975e678b0968e7177d805932276a51e552e29fed0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
