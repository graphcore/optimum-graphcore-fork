{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8698b14a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "241ca065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localdata/paolot/popsdk-venvs/poplar_sdk-ubuntu_20_04-3.1.0+1205-58b501c780/3.1.0+1205_poptorch/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding=utf-8\n",
    "# Copyright 2023 Graphcore Ltd. All rights reserved.\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "\n",
    "\"\"\" Run inference on a ðŸ¤— Whisper model \"\"\"\n",
    "\n",
    "import logging\n",
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import poptorch\n",
    "from optimum.graphcore import IPUConfig, IPUTrainer,IPUTrainingArguments\n",
    "from optimum.graphcore.modeling_utils import to_pipelined\n",
    "from transformers.utils import check_min_version\n",
    "from transformers.utils.versions import require_version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c672ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration, WhisperConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "130d401e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List\n",
    "\n",
    "@dataclass\n",
    "class IPUWhisperConf:\n",
    "    \"\"\"A data class to collect IPU-related config parameters\"\"\"\n",
    "    model_spec: str\n",
    "    layers_per_ipu: List\n",
    "    pod_type: str\n",
    "\n",
    "ipu_whisper = {\n",
    "    \"tiny\": IPUWhisperConf(model_spec='openai/whisper-tiny', layers_per_ipu=[8], pod_type=\"pod1\"),\n",
    "    \"small\": IPUWhisperConf(model_spec='openai/whisper-small', layers_per_ipu=[6,6,6,6], pod_type=\"pod4\"),\n",
    "    \"large\": IPUWhisperConf(model_spec='openai/whisper-large-v2', layers_per_ipu=[4,4,4,4,4,4,4,4, 4,4,4,4,4,4,4,4], pod_type=\"pod16\")\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6731f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"tiny\"\n",
    "iwc = ipu_whisper[model_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "edac9c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate processor and model\n",
    "processor = WhisperProcessor.from_pretrained(iwc.model_spec)\n",
    "model = WhisperForConditionalGeneration.from_pretrained(iwc.model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7cc3e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.use_cache = False    # avoid outputting a lot of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b8a234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_model = WhisperForConditionalGeneration.from_pretrained(iwc.model_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71bef594",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset librispeech_asr_dummy (/home/paolot/.cache/huggingface/datasets/hf-internal-testing___librispeech_asr_dummy/clean/2.1.0/d3bc4c2bc2078fcde3ad0f0f635862e4c0fef78ba94c4a34c4c250a097af240b)\n"
     ]
    }
   ],
   "source": [
    "# load dummy dataset and read soundfiles\n",
    "ds = load_dataset(\"hf-internal-testing/librispeech_asr_dummy\", \"clean\", split=\"validation\")\n",
    "input_features = processor(ds[0][\"audio\"][\"array\"], \n",
    "                           return_tensors=\"pt\",\n",
    "                           sampling_rate=ds[0]['audio']['sampling_rate']).input_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1085e88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "pod_type = os.getenv(\"GRAPHCORE_POD_TYPE\", iwc.pod_type)\n",
    "executable_cache_dir = os.getenv(\"POPLAR_EXECUTABLE_CACHE_DIR\", \"/tmp/whisper_exe_cache/\") + \"whisper_inference\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c54055a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"POPLAR_ENGINE_OPTIONS\"] = f'{{\"autoReport.all\":\"true\", \"debug.instrument\":\"false\", \"debug.allowOutOfMemory\": \"true\", \"autoReport.directory\":\"./profiles/{model_size}\"}}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53887394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment variable setting for debugging\n",
    "# os.environ[\"POPLAR_LOG_LEVEL\"] = \"DEBUG\"\n",
    "# os.environ[\"POPTORCH_LOG_LEVEL\"] = \"TRACE\"\n",
    "# os.environ[\"POPART_LOG_LEVEL\"] = \"DEBUG\"\n",
    "# os.environ[\"POPART_IR_DUMP\"]= \"whisper_ir_dump.log\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd474186",
   "metadata": {},
   "outputs": [],
   "source": [
    "ipu_config = IPUConfig(executable_cache_dir=executable_cache_dir, layers_per_ipu=iwc.layers_per_ipu)\n",
    "opts = ipu_config.to_options(for_inference=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d210b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = IPUTrainingArguments(output_dir=\"/tmp/outputs\",\n",
    "                                     do_train=False,\n",
    "                                     do_eval=False,\n",
    "                                     logging_steps=25,\n",
    "                                     dataloader_num_workers=32,\n",
    "                                     resume_from_checkpoint=True,\n",
    "                                     pad_on_batch_axis=False,\n",
    "                                     pod_type=iwc.pod_type,\n",
    "                                     save_strategy=\"epoch\",\n",
    "                                     report_to=\"none\",\n",
    "#                                      fp32=True,\n",
    "                                     label_names=None\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "199267db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "---------- Device Allocation -----------\n",
      "conv1, conv2, embed_positions  --> IPU 0\n",
      "Encoder 0  --> IPU 0\n",
      "Encoder 1  --> IPU 0\n",
      "Encoder 2  --> IPU 0\n",
      "Encoder 3  --> IPU 0\n",
      "Decoder 0  --> IPU 0\n",
      "Decoder 1  --> IPU 0\n",
      "Decoder 2  --> IPU 0\n",
      "Decoder 3  --> IPU 0\n",
      "Head       --> IPU 0\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "_PopartOptions(instrumentWithHardwareCycleCounter=False, rearrangeAnchorsOnHost=False, cachePath='/tmp/whisper_exe_cache/whisper_inference', enableEngineCaching=True, enableStochasticRounding=False, partialsTypeMatMuls='half', convolutionOptions={'partialsType': 'half'}, disableGradAccumulationTensorStreams=True, accumulateOuterFragmentSettings.schedule=3, accumulateOuterFragmentSettings.excludedVirtualGraphs=['0'], outlineThreshold=10.0, subgraphCopyingStrategy=1, scheduleNonWeightUpdateGradientConsumersEarly=True, patterns_level=2, patterns={'TiedGather': True, 'TiedGatherAccumulate': True, 'UpdateInplacePrioritiesForIpu': True}, engineOptions={'opt.useAutoloader': 'true', 'target.syncReplicasIndependently': 'true'}, saveInitializersToFile='weights.onnx')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = IPUTrainer(model=model, ipu_config=ipu_config, args=training_args)\n",
    "ipt.eval_opts._Popart.set(\"saveInitializersToFile\", \"weights.onnx\")  # needed for larger models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0aa7738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = input_features.half()\n",
    "\n",
    "dataset=Dataset.from_dict({\"audio\": [input_features], \"decoder_input_ids\": [torch.tensor([[50258]])]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "abf97ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compiling Model...\n",
      "Graph compilation: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 100/100 [01:48<00:00]\n",
      "2023-02-09T15:23:38.567652Z popart:devicex 718139.718139 W: Specified directory not found. Creating \"/tmp/whisper_exe_cache/whisper_inference\" directory \n",
      "Compiled/Loaded model in 116.25388805754483 secs\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1\n",
      "  Batch size = 1\n",
      "  0%|                                                                                                                                                                                 | 0/1 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "ipu_results = ipt.predict(test_dataset=dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c939cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-1.606, -2.879,  2.643, ...,  1.016,  2.459,  2.367]]],\n",
       "      dtype=float16)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipu_results.predictions[0]   # logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
